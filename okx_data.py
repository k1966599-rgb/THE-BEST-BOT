#!/usr/bin/env python3
"""
OKX Data Fetcher - Ø¬Ø§Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ù…Ù†ØµØ© OKX
Ù…ØªØ®ØµØµ Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Python
"""

import asyncio
import websockets
import requests
import json
import os
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
from pathlib import Path
import time
import threading
from concurrent.futures import ThreadPoolExecutor

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('okx_data.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

from okx_websocket_client import OKXWebSocketClient

class OKXDataFetcher:
    """
    Fetches historical and REST-based data from OKX.
    Manages the WebSocket client for live data.
    """

    def __init__(self, data_dir: str = 'okx_data'):
        self.base_url = 'https://www.okx.com'
        self.data_dir = Path(data_dir)
        self.price_cache = {}
        self.historical_cache = {}
        self._stop_event = threading.Event()

        # Create an instance of the WebSocket client, passing the shared resources
        self.websocket_client = OKXWebSocketClient(
            price_cache=self.price_cache,
            stop_event=self._stop_event
        )

        # Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        self.default_symbols = [
            'BTC-USDT', 'ETH-USDT', 'BNB-USDT', 'XRP-USDT',
            'ADA-USDT', 'SOL-USDT', 'DOT-USDT', 'DOGE-USDT',
            'MATIC-USDT', 'LTC-USDT', 'LINK-USDT', 'UNI-USDT'
        ]

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._ensure_data_directory()
        logger.info(f"ğŸ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø§Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª OKX - Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {self.data_dir}")

    def _ensure_data_directory(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            self.data_dir.mkdir(exist_ok=True)
            logger.info(f"ğŸ“ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø§Ù‡Ø²: {self.data_dir}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")

    def fetch_current_prices(self, symbols: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        Fetches current prices.
        If symbols is None, fetches for the default list.
        If symbols is an empty list, fetches for ALL available SPOT tickers.
        """
        fetch_all = symbols == []
        symbol_list = self.default_symbols if symbols is None else symbols

        try:
            log_message = "all available tickers" if fetch_all else f"prices for {symbol_list}"
            logger.info(f"ğŸ’° Fetching current {log_message}...")

            response = requests.get(
                f"{self.base_url}/api/v5/market/tickers",
                params={'instType': 'SPOT'},
                headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'},
                timeout=15 # Increased timeout for potentially large response
            )

            if response.status_code == 200:
                data = response.json()

                if data.get('code') == '0':
                    all_tickers = data.get('data', [])
                    processed_prices = {}

                    # Determine which tickers to process
                    tickers_to_process = all_tickers if fetch_all else [t for t in all_tickers if t['instId'] in symbol_list]

                    for ticker in tickers_to_process:
                        symbol = ticker['instId']
                        price_data = {
                            'symbol': symbol,
                            'price': float(ticker['last']),
                            'change_24h': float(ticker.get('chg24h', 0)),
                            'change_percent': float(ticker.get('chgPct24h', 0)),
                            'high_24h': float(ticker.get('high24h', 0)),
                            'low_24h': float(ticker.get('low24h', 0)),
                            'volume': float(ticker.get('vol24h', 0)),
                            'timestamp': int(ticker.get('ts', 0)),
                            'last_update': datetime.now().isoformat()
                        }
                        processed_prices[symbol] = price_data
                        self.price_cache[symbol] = price_data # Update cache

                    self._save_price_data(processed_prices)
                    logger.info(f"âœ… Fetched prices for {len(processed_prices)} symbols.")

                    return processed_prices
                else:
                    raise Exception(f"Ø®Ø·Ø£ Ù…Ù† API: {data.get('msg', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}")
            else:
                raise Exception(f"HTTP Error: {response.status_code}")

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {e}")
            return {}

    def _timeframe_to_minutes(self, timeframe: str) -> int:
        """Converts an OKX timeframe string to minutes for estimations."""
        try:
            if timeframe.endswith('m'):
                return int(timeframe[:-1])
            if timeframe.endswith('H'):
                return int(timeframe[:-1]) * 60
            if timeframe.endswith('D'):
                return int(timeframe[:-1]) * 24 * 60
        except Exception:
            # Fallback for common cases if parsing fails, e.g., '1D' vs '1d'
            if 'D' in timeframe.upper(): return 1440
            if 'H' in timeframe.upper(): return 240
        return 1 # Default to 1 minute to avoid division by zero errors

    def fetch_historical_data(self, symbol: str = 'BTC-USDT', timeframe: str = '1D', days_to_fetch: int = 365) -> List[Dict]:
        """
        Fetches historical data by paginating backwards from the current time.
        It now checks an in-memory cache first to avoid redundant network requests.
        """
        # Check cache first
        if symbol in self.historical_cache:
            logger.info(f"âœ… Found historical data for {symbol} in cache.")
            return self.historical_cache[symbol]

        try:
            logger.info(f"ğŸ“Š Fetching historical data for {symbol} for the last {days_to_fetch} days from network...")

            all_candles = []
            # For the first request, 'before' is None to get the latest data.
            # For subsequent requests, it will be the timestamp of the last fetched candle.
            current_before_ts = None
            endpoint_url = f"{self.base_url}/api/v5/market/candles"
            limit_per_request = 100

            # Approximate the number of requests needed to get the desired number of days
            tf_minutes = self._timeframe_to_minutes(timeframe)
            if tf_minutes <= 0: tf_minutes = 1440 # Default to 1 day if something is wrong
            total_candles_needed = (days_to_fetch * 24 * 60) / tf_minutes
            num_requests = int(total_candles_needed / limit_per_request) + 2

            for i in range(num_requests):
                params = {
                    'instId': symbol,
                    'bar': timeframe,
                    'limit': str(limit_per_request)
                }
                if current_before_ts:
                    params['before'] = current_before_ts

                logger.info(f"Requesting chunk {i+1}/{num_requests} from OKX API with params: {params}")

                response = requests.get(
                    endpoint_url,
                    params=params,
                    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'},
                    timeout=15
                )

                if response.status_code == 200:
                    data = response.json()
                    if data.get('code') == '0':
                        candles_data = data.get('data', [])
                        if not candles_data:
                            logger.info("API returned no more candle data. Stopping fetch.")
                            break

                        all_candles.extend(candles_data)
                        current_before_ts = candles_data[-1][0]
                        time.sleep(0.25)
                    else:
                        raise Exception(f"API Error: {data.get('msg', 'Unknown error')}")
                else:
                    raise Exception(f"HTTP Error: {response.status_code} - {response.text}")

            # Process all fetched candles
            historical_data = []
            seen_timestamps = set()
            for candle in all_candles:
                timestamp = int(candle[0])
                if timestamp not in seen_timestamps:
                    historical_data.append({
                        'timestamp': timestamp,
                        'open': float(candle[1]),
                        'high': float(candle[2]),
                        'low': float(candle[3]),
                        'close': float(candle[4]),
                        'volume': float(candle[5]),
                        'date': datetime.fromtimestamp(timestamp / 1000).isoformat()
                    })
                    seen_timestamps.add(timestamp)

            # Sort data by timestamp ascending
            historical_data.sort(key=lambda x: x['timestamp'])

            # Save and cache the data
            self._save_historical_data(symbol, historical_data)
            self.historical_cache[symbol] = historical_data

            logger.info(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(historical_data)} Ø´Ù…Ø¹Ø© ØªØ§Ø±ÙŠØ®ÙŠØ© ÙØ±ÙŠØ¯Ø© Ù„Ù€ {symbol}")
            return historical_data

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù€ {symbol}: {e}")
            return []


    def _save_price_data(self, prices: Dict[str, Any]):
        """Ø­ÙØ¸ Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù„Ø­Ø¸Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
        try:
            filename = self.data_dir / 'current_prices.json'
            data_to_save = {
                'prices': prices,
                'last_update': datetime.now().isoformat(),
                'total_symbols': len(prices)
            }

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, indent=2, ensure_ascii=False)

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø±: {e}")

    def _save_historical_data(self, symbol: str, data: List[Dict]):
        """Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©"""
        try:
            filename = self.data_dir / f"{symbol.replace('/', '-')}_historical.json"
            data_to_save = {
                'symbol': symbol,
                'data': data,
                'last_update': datetime.now().isoformat(),
                'total_records': len(data)
            }

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, indent=2, ensure_ascii=False)

            logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©: {filename}")

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù€ {symbol}: {e}")

    def get_cached_price(self, symbol: str) -> Optional[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¹Ø± Ù…Ù† Ø§Ù„ÙƒØ§Ø´"""
        return self.price_cache.get(symbol)

    def get_cached_historical_data(self, symbol: str) -> Optional[List[Dict]]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† Ø§Ù„ÙƒØ§Ø´"""
        return self.historical_cache.get(symbol)

    def analyze_trend(self, symbol: str, period: int = 20) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©"""
        historical = self.get_cached_historical_data(symbol)

        if not historical or len(historical) < period:
            return {'trend': 'ØºÙŠØ± ÙƒØ§ÙÙŠ', 'confidence': 0, 'sma': None}

        # Ø£Ø®Ø° Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø©
        recent_data = historical[-period:]
        prices = [d['close'] for d in recent_data]

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ø§Ù„Ø¨Ø³ÙŠØ·
        sma = sum(prices) / len(prices)
        current_price_data = self.get_cached_price(symbol)
        current_price = current_price_data['price'] if current_price_data else prices[-1]

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
        trend = 'Ø¬Ø§Ù†Ø¨ÙŠ'
        confidence = 0

        if current_price > sma * 1.02:
            trend = 'ØµØ§Ø¹Ø¯'
            confidence = min(((current_price - sma) / sma) * 100, 100)
        elif current_price < sma * 0.98:
            trend = 'Ù‡Ø§Ø¨Ø·'
            confidence = min(((sma - current_price) / sma) * 100, 100)

        return {
            'trend': trend,
            'confidence': round(confidence),
            'sma': round(sma, 2),
            'current_price': current_price,
            'analysis_time': datetime.now().isoformat()
        }

    def calculate_rsi(self, symbol: str, period: int = 14) -> Optional[float]:
        """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ© RSI"""
        historical = self.get_cached_historical_data(symbol)

        if not historical or len(historical) < period + 1:
            return None

        prices = [d['close'] for d in historical[-period-1:]]

        gains = []
        losses = []

        for i in range(1, len(prices)):
            change = prices[i] - prices[i-1]
            gains.append(change if change > 0 else 0)
            losses.append(abs(change) if change < 0 else 0)

        avg_gain = sum(gains[-period:]) / period
        avg_loss = sum(losses[-period:]) / period

        if avg_loss == 0:
            return 100

        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))

        return round(rsi, 2)

    def get_trading_signals(self, symbol: str) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„"""
        trend = self.analyze_trend(symbol)
        rsi = self.calculate_rsi(symbol)
        current_price = self.get_cached_price(symbol)

        signals = {
            'symbol': symbol,
            'timestamp': datetime.now().isoformat(),
            'price': current_price['price'] if current_price else None,
            'trend': trend,
            'rsi': rsi,
            'signals': []
        }

        # Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„
        if rsi and rsi < 30 and trend['trend'] == 'ØµØ§Ø¹Ø¯':
            signals['signals'].append({
                'type': 'Ø´Ø±Ø§Ø¡ Ù‚ÙˆÙŠ',
                'reason': 'RSI Ù…Ù†Ø®ÙØ¶ + Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯',
                'confidence': min(trend['confidence'] + 20, 100)
            })
        elif rsi and rsi > 70 and trend['trend'] == 'Ù‡Ø§Ø¨Ø·':
            signals['signals'].append({
                'type': 'Ø¨ÙŠØ¹ Ù‚ÙˆÙŠ',
                'reason': 'RSI Ù…Ø±ØªÙØ¹ + Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø·',
                'confidence': min(trend['confidence'] + 20, 100)
            })
        elif rsi and rsi < 35:
            signals['signals'].append({
                'type': 'Ø´Ø±Ø§Ø¡',
                'reason': 'RSI Ù…Ù†Ø®ÙØ¶',
                'confidence': 60
            })
        elif rsi and rsi > 65:
            signals['signals'].append({
                'type': 'Ø¨ÙŠØ¹',
                'reason': 'RSI Ù…Ø±ØªÙØ¹',
                'confidence': 60
            })

        return signals

    def get_market_overview(self) -> Dict[str, Any]:
        """Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙˆÙ‚"""
        overview = {
            'timestamp': datetime.now().isoformat(),
            'total_symbols': len(self.price_cache),
            'connected': self.websocket_client.is_connected,
            'top_gainers': [],
            'top_losers': [],
            'market_summary': {
                'bullish': 0,
                'bearish': 0,
                'neutral': 0
            }
        }

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª
        symbol_analysis = []
        for symbol in self.default_symbols:
            price_data = self.get_cached_price(symbol)
            if price_data:
                trend = self.analyze_trend(symbol)
                symbol_analysis.append({
                    'symbol': symbol,
                    'change_percent': price_data['change_percent'],
                    'trend': trend['trend']
                })

        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø±Ø§Ø¨Ø­ÙŠÙ† ÙˆØ§Ù„Ø®Ø§Ø³Ø±ÙŠÙ†
        symbol_analysis.sort(key=lambda x: x['change_percent'], reverse=True)
        overview['top_gainers'] = symbol_analysis[:5]
        overview['top_losers'] = symbol_analysis[-5:]

        # Ù…Ù„Ø®Øµ Ø§Ù„Ø³ÙˆÙ‚
        for analysis in symbol_analysis:
            if analysis['trend'] == 'ØµØ§Ø¹Ø¯':
                overview['market_summary']['bullish'] += 1
            elif analysis['trend'] == 'Ù‡Ø§Ø¨Ø·':
                overview['market_summary']['bearish'] += 1
            else:
                overview['market_summary']['neutral'] += 1

        return overview

    def start_full_data_collection(self, symbols: List[str] = None):
        """Ø¨Ø¯Ø¡ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
        if symbols is None:
            symbols = self.default_symbols

        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©...")

        # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ÙÙŠ thread Ù…Ù†ÙØµÙ„
        def fetch_all_historical():
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = []
                for symbol in symbols:
                    future = executor.submit(self.fetch_historical_data, symbol)
                    futures.append(future)
                    time.sleep(0.1)  # ØªØ£Ø®ÙŠØ± Ù‚ØµÙŠØ± Ø¨ÙŠÙ† Ø§Ù„Ø·Ù„Ø¨Ø§Øª

                # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ù…
                for future in futures:
                    try:
                        future.result()
                    except Exception as e:
                        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©: {e}")

        # Ø¨Ø¯Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
        historical_thread = threading.Thread(target=fetch_all_historical)
        historical_thread.start()

        # Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        self.fetch_current_prices(symbols)

        # Start the WebSocket client
        self.websocket_client.start(symbols)

        # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
        historical_thread.join()

        logger.info("âœ… ØªÙ… Ø¨Ø¯Ø¡ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")

    def stop(self):
        """Signals all running threads to stop."""
        logger.info("â¹ï¸ Stopping data fetcher...")
        self._stop_event.set()
        self.is_connected = False
        # The websocket thread will see the event and exit gracefully.
        logger.info("âœ… Stop signal sent to data fetcher.")

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø§Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    okx_fetcher = OKXDataFetcher()

    try:
        # Ø¨Ø¯Ø¡ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        symbols = ['BTC-USDT', 'ETH-USDT', 'BNB-USDT', 'XRP-USDT']
        okx_fetcher.start_full_data_collection(symbols)

        # Ø§Ù†ØªØ¸Ø§Ø± Ù‚ØµÙŠØ± Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        time.sleep(10)

        # Ø¹Ø±Ø¶ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print("\nğŸ“Š Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        btc_price = okx_fetcher.get_cached_price('BTC-USDT')
        if btc_price:
            print(f"ğŸª™ BTC: ${btc_price['price']:.2f} ({btc_price['change_percent']:+.2f}%)")

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
        btc_analysis = okx_fetcher.analyze_trend('BTC-USDT')
        print(f"ğŸ“ˆ BTC Ø§Ù„Ø§ØªØ¬Ø§Ù‡: {btc_analysis['trend']} (Ø«Ù‚Ø©: {btc_analysis['confidence']}%)")

        # Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„
        signals = okx_fetcher.get_trading_signals('BTC-USDT')
        if signals['signals']:
            for signal in signals['signals']:
                print(f"ğŸ¯ Ø¥Ø´Ø§Ø±Ø©: {signal['type']} - {signal['reason']} (Ø«Ù‚Ø©: {signal['confidence']}%)")

        # Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙˆÙ‚
        overview = okx_fetcher.get_market_overview()
        print(f"\nğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø³ÙˆÙ‚:")
        print(f"   ğŸ“ˆ ØµØ§Ø¹Ø¯: {overview['market_summary']['bullish']}")
        print(f"   ğŸ“‰ Ù‡Ø§Ø¨Ø·: {overview['market_summary']['bearish']}")
        print(f"   â¡ï¸ Ø¬Ø§Ù†Ø¨ÙŠ: {overview['market_summary']['neutral']}")

        # Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙŠØ¹Ù…Ù„
        print("\nâŒ¨ï¸ Ø§Ø¶ØºØ· Ctrl+C Ù„Ù„Ø¥ÙŠÙ‚Ø§Ù...")
        try:
            while True:
                time.sleep(60)  # ØªØ­Ø¯ÙŠØ« ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø©
                overview = okx_fetcher.get_market_overview()
                print(f"ğŸ”„ {datetime.now().strftime('%H:%M:%S')} - Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Øª: {overview['total_symbols']} | Ù…ØªØµÙ„: {'âœ…' if overview['connected'] else 'âŒ'}")
        except KeyboardInterrupt:
            pass

    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: {e}")
    finally:
        okx_fetcher.stop()
